{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import supervision as sv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input output paths\n",
    "video_path = '../data/inputs/lebron_1.mp4'\n",
    "output_dir = '/Users/treyshanks/data_science/Court_Vision/data/outputs/anotated_ouput.mp4'\n",
    "output_dir_aug = '/Users/treyshanks/data_science/Court_Vision/data/outputs/anotated_ouput_aug.mp4'\n",
    "\n",
    "model_aug_path = '/Users/treyshanks/data_science/Court_Vision/notebooks/lebron_aug_best.pt'\n",
    "first_model_path = '/Users/treyshanks/data_science/Court_Vision/lebron_collab/weights/best.pt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Fine-tuning --> \n",
    "identify type of video - camera angle, single game or continuous video\n",
    "log findings from inference?\n",
    "does the model track boxes frame to frame -- player tracking?\n",
    "identify teams? identify a specific player and location? \n",
    "metric -- player movement? \n",
    "fixed camera angel vs jump cuts?\n",
    "Need to identify what kind of video to run inference on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input output paths\n",
    "video_path = '../data/inputs/lebron_short_1.mp4'\n",
    "output_dir = '/Users/treyshanks/data_science/Court_Vision/data/outputs/anotated_ouput.mp4'\n",
    "output_dir_aug = '/Users/treyshanks/data_science/Court_Vision/data/outputs/anotated_ouput_aug.mp4'\n",
    "\n",
    "model_aug_path = '/Users/treyshanks/data_science/Court_Vision/notebooks/lebron_aug_best.pt'\n",
    "first_model_path = '/Users/treyshanks/data_science/Court_Vision/lebron_collab/weights/best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "model = YOLO(model_aug_path)\n",
    "model.model.to(device)\n",
    "\n",
    "tracker = sv.ByteTrack()\n",
    "box_annotator = sv.BoundingBoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "def callback(frame: np.ndarray, _: int) -> np.ndarray:\n",
    "    results = model(frame)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    tracked_detections = tracker.update_with_detections(detections)\n",
    "\n",
    "    # generate tracking labels\n",
    "    labels = [\n",
    "        f\"{model.model.names[class_id]} {confidence:.2f}\"\n",
    "        for class_id, tracker_id, confidence in zip(tracked_detections.class_id, tracked_detections.tracker_id, tracked_detections.confidence)\n",
    "    ]\n",
    "\n",
    "    if len(labels) != len(detections):\n",
    "        print(f\"The number of labels provided ({len(labels)}) does not match the number of detections ({len(detections)}).\")\n",
    "        return frame\n",
    "\n",
    "    # Annotate the frame with the filtered detections\n",
    "    annotated_frame = box_annotator.annotate(frame.copy(), detections=detections)\n",
    "    annotated_frame = label_annotator.annotate(annotated_frame, detections=detections, labels=labels)\n",
    "    \n",
    "    return annotated_frame\n",
    "\n",
    "# Process the video\n",
    "sv.process_video(\n",
    "    source_path=video_path,\n",
    "    target_path=output_dir_aug,\n",
    "    callback=callback\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
